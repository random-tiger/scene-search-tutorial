{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Searching for specific scenes in a movie can be time-consuming. By combining video processing, AI-generated captions, and embeddings, we can create a powerful tool that allows users to find scenes based on textual descriptions. This tool extracts key frames from a video, generates captions for each frame, computes embeddings, and allows users to search through the scenes using natural language queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Required Libraries\n",
    "Install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install opencv-python\n",
    "%pip install scikit-learn\n",
    "%pip install scenedetect\n",
    "%pip install PySceneDetect\n",
    "%pip install boto3\n",
    "%pip install pandas\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bbassett/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scenedetect import VideoManager, SceneManager\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from IPython.display import Image, display\n",
    "import concurrent.futures\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing OpenAI Client\n",
    "Initialize the OpenAI client using your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# Initializing OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3 Configuration\n",
    "Set up your AWS S3 client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Credentials\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# AWS S3 Configuration\n",
    "s3_bucket_name = 'video-clips-test'\n",
    "s3_region = 'us-east-2'\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3',\n",
    "                  region_name=s3_region,\n",
    "                  aws_access_key_id=aws_access_key_id,\n",
    "                  aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'your-s3-bucket-name' and 'your-s3-region' with your AWS S3 bucket name and region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Video from S3\n",
    "We'll start by downloading the video file from AWS S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download video from S3\n",
    "def download_video_from_s3(s3_bucket, s3_key, local_path):\n",
    "    s3.download_file(s3_bucket, s3_key, local_path)\n",
    "    print(f\"Downloaded {s3_key} from S3 to {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function with the appropriate parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded movie.mp4 from S3 to movie.mp4\n"
     ]
    }
   ],
   "source": [
    "# Video S3 key (path within the bucket)\n",
    "s3_video_key = 'movie.mp4'  # Update if your video is stored under a different key\n",
    "\n",
    "# Local path to save the video\n",
    "video_local_path = 'movie.mp4'  # Save in the current working directory\n",
    "\n",
    "# Download the video from S3\n",
    "download_video_from_s3(s3_bucket_name, s3_video_key, video_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Key Frames from Video\n",
    "Next, we'll extract key frames from the video using PySceneDetect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract key frames from video\n",
    "def extract_key_frames(video_path, output_dir):\n",
    "    import os\n",
    "    import cv2\n",
    "    from scenedetect import VideoManager, SceneManager\n",
    "    from scenedetect.detectors import ContentDetector\n",
    "\n",
    "    # Create a VideoManager object\n",
    "    video_manager = VideoManager([video_path])\n",
    "    # Create a SceneManager object\n",
    "    scene_manager = SceneManager()\n",
    "    # Add ContentDetector algorithm (detects fast cuts)\n",
    "    scene_manager.add_detector(ContentDetector(threshold=30.0))\n",
    "\n",
    "    # Start the video manager and perform scene detection\n",
    "    try:\n",
    "        video_manager.start()\n",
    "        scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scene detection: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Get list of detected scenes\n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "    if not scene_list:\n",
    "        print(\"No scenes were detected in the video.\")\n",
    "        return []\n",
    "    else:\n",
    "        print(f\"Detected {len(scene_list)} scenes in video.\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open video file using OpenCV\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video file {video_path}\")\n",
    "        return []\n",
    "\n",
    "    # Save the first frame of each scene\n",
    "    frame_list = []\n",
    "    total_scenes = len(scene_list)\n",
    "    for i, scene in enumerate(scene_list):\n",
    "        print(f\"Processing scene {i + 1}/{total_scenes}\")\n",
    "        # Access the start timecode of the scene\n",
    "        start_timecode = scene[0]\n",
    "        # Get the frame number\n",
    "        start_frame = start_timecode.get_frames()\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{i}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            frame_list.append(frame_filename)\n",
    "        else:\n",
    "            print(f\"Failed to read frame at position {start_frame}\")\n",
    "    cap.release()\n",
    "    video_manager.release()  # Release the video manager resources\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VideoManager is deprecated and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 308 scenes in video.\n",
      "Processing scene 1/308\n",
      "Processing scene 2/308\n",
      "Processing scene 3/308\n",
      "Processing scene 4/308\n",
      "Processing scene 5/308\n",
      "Processing scene 6/308\n",
      "Processing scene 7/308\n",
      "Processing scene 8/308\n",
      "Processing scene 9/308\n",
      "Processing scene 10/308\n",
      "Processing scene 11/308\n",
      "Processing scene 12/308\n",
      "Processing scene 13/308\n",
      "Processing scene 14/308\n",
      "Processing scene 15/308\n",
      "Processing scene 16/308\n",
      "Processing scene 17/308\n",
      "Processing scene 18/308\n",
      "Processing scene 19/308\n",
      "Processing scene 20/308\n",
      "Processing scene 21/308\n",
      "Processing scene 22/308\n",
      "Processing scene 23/308\n",
      "Processing scene 24/308\n",
      "Processing scene 25/308\n",
      "Processing scene 26/308\n",
      "Processing scene 27/308\n",
      "Processing scene 28/308\n",
      "Processing scene 29/308\n",
      "Processing scene 30/308\n",
      "Processing scene 31/308\n",
      "Processing scene 32/308\n",
      "Processing scene 33/308\n",
      "Processing scene 34/308\n",
      "Processing scene 35/308\n",
      "Processing scene 36/308\n",
      "Processing scene 37/308\n",
      "Processing scene 38/308\n",
      "Processing scene 39/308\n",
      "Processing scene 40/308\n",
      "Processing scene 41/308\n",
      "Processing scene 42/308\n",
      "Processing scene 43/308\n",
      "Processing scene 44/308\n",
      "Processing scene 45/308\n",
      "Processing scene 46/308\n",
      "Processing scene 47/308\n",
      "Processing scene 48/308\n",
      "Processing scene 49/308\n",
      "Processing scene 50/308\n",
      "Processing scene 51/308\n",
      "Processing scene 52/308\n",
      "Processing scene 53/308\n",
      "Processing scene 54/308\n",
      "Processing scene 55/308\n",
      "Processing scene 56/308\n",
      "Processing scene 57/308\n",
      "Processing scene 58/308\n",
      "Processing scene 59/308\n",
      "Processing scene 60/308\n",
      "Processing scene 61/308\n",
      "Processing scene 62/308\n",
      "Processing scene 63/308\n",
      "Processing scene 64/308\n",
      "Processing scene 65/308\n",
      "Processing scene 66/308\n",
      "Processing scene 67/308\n",
      "Processing scene 68/308\n",
      "Processing scene 69/308\n",
      "Processing scene 70/308\n",
      "Processing scene 71/308\n",
      "Processing scene 72/308\n",
      "Processing scene 73/308\n",
      "Processing scene 74/308\n",
      "Processing scene 75/308\n",
      "Processing scene 76/308\n",
      "Processing scene 77/308\n",
      "Processing scene 78/308\n",
      "Processing scene 79/308\n",
      "Processing scene 80/308\n",
      "Processing scene 81/308\n",
      "Processing scene 82/308\n",
      "Processing scene 83/308\n",
      "Processing scene 84/308\n",
      "Processing scene 85/308\n",
      "Processing scene 86/308\n",
      "Processing scene 87/308\n",
      "Processing scene 88/308\n",
      "Processing scene 89/308\n",
      "Processing scene 90/308\n",
      "Processing scene 91/308\n",
      "Processing scene 92/308\n",
      "Processing scene 93/308\n",
      "Processing scene 94/308\n",
      "Processing scene 95/308\n",
      "Processing scene 96/308\n",
      "Processing scene 97/308\n",
      "Processing scene 98/308\n",
      "Processing scene 99/308\n",
      "Processing scene 100/308\n",
      "Processing scene 101/308\n",
      "Processing scene 102/308\n",
      "Processing scene 103/308\n",
      "Processing scene 104/308\n",
      "Processing scene 105/308\n",
      "Processing scene 106/308\n",
      "Processing scene 107/308\n",
      "Processing scene 108/308\n",
      "Processing scene 109/308\n",
      "Processing scene 110/308\n",
      "Processing scene 111/308\n",
      "Processing scene 112/308\n",
      "Processing scene 113/308\n",
      "Processing scene 114/308\n",
      "Processing scene 115/308\n",
      "Processing scene 116/308\n",
      "Processing scene 117/308\n",
      "Processing scene 118/308\n",
      "Processing scene 119/308\n",
      "Processing scene 120/308\n",
      "Processing scene 121/308\n",
      "Processing scene 122/308\n",
      "Processing scene 123/308\n",
      "Processing scene 124/308\n",
      "Processing scene 125/308\n",
      "Processing scene 126/308\n",
      "Processing scene 127/308\n",
      "Processing scene 128/308\n",
      "Processing scene 129/308\n",
      "Processing scene 130/308\n",
      "Processing scene 131/308\n",
      "Processing scene 132/308\n",
      "Processing scene 133/308\n",
      "Processing scene 134/308\n",
      "Processing scene 135/308\n",
      "Processing scene 136/308\n",
      "Processing scene 137/308\n",
      "Processing scene 138/308\n",
      "Processing scene 139/308\n",
      "Processing scene 140/308\n",
      "Processing scene 141/308\n",
      "Processing scene 142/308\n",
      "Processing scene 143/308\n",
      "Processing scene 144/308\n",
      "Processing scene 145/308\n",
      "Processing scene 146/308\n",
      "Processing scene 147/308\n",
      "Processing scene 148/308\n",
      "Processing scene 149/308\n",
      "Processing scene 150/308\n",
      "Processing scene 151/308\n",
      "Processing scene 152/308\n",
      "Processing scene 153/308\n",
      "Processing scene 154/308\n",
      "Processing scene 155/308\n",
      "Processing scene 156/308\n",
      "Processing scene 157/308\n",
      "Processing scene 158/308\n",
      "Processing scene 159/308\n",
      "Processing scene 160/308\n",
      "Processing scene 161/308\n",
      "Processing scene 162/308\n",
      "Processing scene 163/308\n",
      "Processing scene 164/308\n",
      "Processing scene 165/308\n",
      "Processing scene 166/308\n",
      "Processing scene 167/308\n",
      "Processing scene 168/308\n",
      "Processing scene 169/308\n",
      "Processing scene 170/308\n",
      "Processing scene 171/308\n",
      "Processing scene 172/308\n",
      "Processing scene 173/308\n",
      "Processing scene 174/308\n",
      "Processing scene 175/308\n",
      "Processing scene 176/308\n",
      "Processing scene 177/308\n",
      "Processing scene 178/308\n",
      "Processing scene 179/308\n",
      "Processing scene 180/308\n",
      "Processing scene 181/308\n",
      "Processing scene 182/308\n",
      "Processing scene 183/308\n",
      "Processing scene 184/308\n",
      "Processing scene 185/308\n",
      "Processing scene 186/308\n",
      "Processing scene 187/308\n",
      "Processing scene 188/308\n",
      "Processing scene 189/308\n",
      "Processing scene 190/308\n",
      "Processing scene 191/308\n",
      "Processing scene 192/308\n",
      "Processing scene 193/308\n",
      "Processing scene 194/308\n",
      "Processing scene 195/308\n",
      "Processing scene 196/308\n",
      "Processing scene 197/308\n",
      "Processing scene 198/308\n",
      "Processing scene 199/308\n",
      "Processing scene 200/308\n",
      "Processing scene 201/308\n",
      "Processing scene 202/308\n",
      "Processing scene 203/308\n",
      "Processing scene 204/308\n",
      "Processing scene 205/308\n",
      "Processing scene 206/308\n",
      "Processing scene 207/308\n",
      "Processing scene 208/308\n",
      "Processing scene 209/308\n",
      "Processing scene 210/308\n",
      "Processing scene 211/308\n",
      "Processing scene 212/308\n",
      "Processing scene 213/308\n",
      "Processing scene 214/308\n",
      "Processing scene 215/308\n",
      "Processing scene 216/308\n",
      "Processing scene 217/308\n",
      "Processing scene 218/308\n",
      "Processing scene 219/308\n",
      "Processing scene 220/308\n",
      "Processing scene 221/308\n",
      "Processing scene 222/308\n",
      "Processing scene 223/308\n",
      "Processing scene 224/308\n",
      "Processing scene 225/308\n",
      "Processing scene 226/308\n",
      "Processing scene 227/308\n",
      "Processing scene 228/308\n",
      "Processing scene 229/308\n",
      "Processing scene 230/308\n",
      "Processing scene 231/308\n",
      "Processing scene 232/308\n",
      "Processing scene 233/308\n",
      "Processing scene 234/308\n",
      "Processing scene 235/308\n",
      "Processing scene 236/308\n",
      "Processing scene 237/308\n",
      "Processing scene 238/308\n",
      "Processing scene 239/308\n",
      "Processing scene 240/308\n",
      "Processing scene 241/308\n",
      "Processing scene 242/308\n",
      "Processing scene 243/308\n",
      "Processing scene 244/308\n",
      "Processing scene 245/308\n",
      "Processing scene 246/308\n",
      "Processing scene 247/308\n",
      "Processing scene 248/308\n",
      "Processing scene 249/308\n",
      "Processing scene 250/308\n",
      "Processing scene 251/308\n",
      "Processing scene 252/308\n",
      "Processing scene 253/308\n",
      "Processing scene 254/308\n",
      "Processing scene 255/308\n",
      "Processing scene 256/308\n",
      "Processing scene 257/308\n",
      "Processing scene 258/308\n",
      "Processing scene 259/308\n",
      "Processing scene 260/308\n",
      "Processing scene 261/308\n",
      "Processing scene 262/308\n",
      "Processing scene 263/308\n",
      "Processing scene 264/308\n",
      "Processing scene 265/308\n",
      "Processing scene 266/308\n",
      "Processing scene 267/308\n",
      "Processing scene 268/308\n",
      "Processing scene 269/308\n",
      "Processing scene 270/308\n",
      "Processing scene 271/308\n",
      "Processing scene 272/308\n",
      "Processing scene 273/308\n",
      "Processing scene 274/308\n",
      "Processing scene 275/308\n",
      "Processing scene 276/308\n",
      "Processing scene 277/308\n",
      "Processing scene 278/308\n",
      "Processing scene 279/308\n",
      "Processing scene 280/308\n",
      "Processing scene 281/308\n",
      "Processing scene 282/308\n",
      "Processing scene 283/308\n",
      "Processing scene 284/308\n",
      "Processing scene 285/308\n",
      "Processing scene 286/308\n",
      "Processing scene 287/308\n",
      "Processing scene 288/308\n",
      "Processing scene 289/308\n",
      "Processing scene 290/308\n",
      "Processing scene 291/308\n",
      "Processing scene 292/308\n",
      "Processing scene 293/308\n",
      "Processing scene 294/308\n",
      "Processing scene 295/308\n",
      "Processing scene 296/308\n",
      "Processing scene 297/308\n",
      "Processing scene 298/308\n",
      "Processing scene 299/308\n",
      "Processing scene 300/308\n",
      "Processing scene 301/308\n",
      "Processing scene 302/308\n",
      "Processing scene 303/308\n",
      "Processing scene 304/308\n",
      "Processing scene 305/308\n",
      "Processing scene 306/308\n",
      "Processing scene 307/308\n",
      "Processing scene 308/308\n"
     ]
    }
   ],
   "source": [
    "# Output directory for frames\n",
    "output_dir = 'frames'  # Local directory to save frames\n",
    "\n",
    "# Extract key frames from the video\n",
    "frame_list = extract_key_frames(video_local_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Images to S3\n",
    "We'll upload the extracted frames to S3 and get their public URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload image to S3 and get public URL\n",
    "def upload_image_to_s3(image_path, s3_bucket, s3_folder='frames'):\n",
    "    file_name = os.path.basename(image_path)\n",
    "    s3_key = f\"{s3_folder}/{file_name}\"\n",
    "    s3.upload_file(image_path, s3_bucket, s3_key)\n",
    "    image_url = f\"https://{s3_bucket}.s3.{s3_region}.amazonaws.com/{s3_key}\"\n",
    "    return image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Captions with OpenAI\n",
    "We'll generate captions for each frame using OpenAI's GPT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate captions using OpenAI's gpt-4o-mini model\n",
    "def generate_caption(image_url):\n",
    "    caption_system_prompt = '''\n",
    "    You are an assistant that generates concise captions for images. These captions will be embedded and stored so \n",
    "    people can semantically search for scenes. Ensure your captions include:\n",
    "    - Physical descriptions of people\n",
    "    - Identify and name of key actors\n",
    "    - Descriptions of key scene objects such as their color\n",
    "    - The mood of the scene\n",
    "    - The actions or activites taking place in the scene\n",
    "    '''\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": caption_system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": image_url,\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Embeddings\n",
    "Compute embeddings for the captions using OpenAI's embedding models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings\n",
    "def get_embedding(value, model=\"text-embedding-3-large\"): \n",
    "    embeddings = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=value,\n",
    "        encoding_format=\"float\"\n",
    "    )\n",
    "    return embeddings.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Frames Based on a Prompt\n",
    "We'll search for frames that are most similar to a user's query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search frames based on a prompt\n",
    "def search_frames(prompt, df_frames, top_n=5):\n",
    "    prompt_embedding = get_embedding(prompt)\n",
    "    df_frames['similarity'] = df_frames['embedding'].apply(\n",
    "        lambda x: cosine_similarity(np.array(x).reshape(1, -1), np.array(prompt_embedding).reshape(1, -1))[0][0]\n",
    "    )\n",
    "    results = df_frames.sort_values('similarity', ascending=False).head(top_n)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together\n",
    "We'll process each frame, generate captions and embeddings, and store the data in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single frame\n",
    "def process_frame(frame_filename):\n",
    "    # Upload image to S3 and get the URL\n",
    "    image_url = upload_image_to_s3(frame_filename, s3_bucket_name)\n",
    "    # Generate caption\n",
    "    caption = generate_caption(image_url)\n",
    "    # Generate embedding\n",
    "    embedding = get_embedding(caption)\n",
    "    # Return frame data\n",
    "    return {\n",
    "        'frame_filename': frame_filename,\n",
    "        'image_url': image_url,\n",
    "        'caption': caption,\n",
    "        'embedding': embedding\n",
    "    }\n",
    "\n",
    "# Process frames in parallel\n",
    "frame_data_list = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = executor.map(process_frame, frame_list)\n",
    "    frame_data_list = list(results)\n",
    "\n",
    "# Create DataFrame\n",
    "df_frames = pd.DataFrame(frame_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Query and Displaying Results\n",
    "Now, let's allow the user to search for scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: frames/frame_183.jpg\n",
      "Caption: A close-up of a male driver with short, light brown hair and intense blue eyes, looking focused and serious while seated in a car. The interior is dimly lit, with a blue hue illuminating his face, suggesting a tense or dramatic mood. The background is blurred, indicating high speed or movement.\n",
      "Similarity: 0.5480666149492754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://video-clips-test.s3.us-east-2.amazonaws.com/frames/frame_183.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: frames/frame_21.jpg\n",
      "Caption: A close-up shot of a young man with short, light brown hair and striking blue eyes, sitting in a car. The scene is illuminated with a blue hue, creating a tense and focused atmosphere. The man appears serious and contemplative, possibly preparing for a race or a significant moment. The interior of the car is visible, with racing seats in the background.\n",
      "Similarity: 0.5474135337296182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://video-clips-test.s3.us-east-2.amazonaws.com/frames/frame_21.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: frames/frame_193.jpg\n",
      "Caption: A man with short, light-colored hair is driving a car, wearing a white shirt. The interior of the vehicle is illuminated with blue lights, creating a dynamic and intense atmosphere. The scene conveys a sense of speed and excitement, as the car appears to be in motion.\n",
      "Similarity: 0.510289437589817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://video-clips-test.s3.us-east-2.amazonaws.com/frames/frame_193.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: frames/frame_156.jpg\n",
      "Caption: A tense scene inside a car featuring a man with short, light brown hair and a serious expression. He is wearing a white shirt and a racing harness. The interior is dimly lit with blue tones, suggesting a high-stakes moment. The background hints at a nighttime setting with colorful lights, indicating a racing or street racing atmosphere.\n",
      "Similarity: 0.4919880567964413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://video-clips-test.s3.us-east-2.amazonaws.com/frames/frame_156.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: frames/frame_120.jpg\n",
      "Caption: A young man with short, light brown hair is seated in a car, wearing a white t-shirt and a racing harness. The interior is dimly lit with blue tones, creating a tense atmosphere. He appears focused and slightly tense, gripping the steering wheel as if preparing for action. The background suggests a nighttime setting, possibly on a street or racetrack.\n",
      "Similarity: 0.48366245830524235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://video-clips-test.s3.us-east-2.amazonaws.com/frames/frame_120.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Find images of Paul Walker, a blonde hair blue-eyed man, in a car.\"\n",
    "results = search_frames(prompt, df_frames, top_n=5)\n",
    "\n",
    "# Display the results\n",
    "for index, row in results.iterrows():\n",
    "    print(f\"Frame: {row['frame_filename']}\")\n",
    "    print(f\"Caption: {row['caption']}\")\n",
    "    print(f\"Similarity: {row['similarity']}\")\n",
    "    display(Image(url=row['image_url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
